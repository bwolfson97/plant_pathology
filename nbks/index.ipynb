{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from plant_pathology.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Pathology Classifier\n",
    "\n",
    "> A neural network that takes in an image of a leaf and classifies the leaf as healthy or diseased!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A picture of a leaf](../example_image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently, I've been learning about [Fast.ai](https://docs.fast.ai/) and [PyTorch](https://pytorch.org/) in my free time and wanted to apply my knowledge. I'm trying to learn how to win Kaggle competitions, so I decided to build a model for the completed Kaggle [Plant Pathology Competition](https://www.kaggle.com/c/plant-pathology-2020-fgvc7/overview).\n",
    "\n",
    "I built this model using [Nbdev](https://nbdev.fast.ai/), which provides an [literate programming](https://en.wikipedia.org/wiki/Literate_programming) environment as originally envisioned by Donald Knuth. This means the notebooks in the `nbks` folder are the library's \"source code\". They get converted into regular python files, a full documentation site, and contain unit and functional test, all in one place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install plant_pathology`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plant_pathology.pretrained_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-14608c339b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplant_pathology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**FIXME**\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plant_pathology.pretrained_models'"
     ]
    }
   ],
   "source": [
    "from plant_pathology.pretrained_models import get_model\n",
    "\n",
    "model = get_model(\"**FIXME**\")\n",
    "prediction = model.predict(\"/path/to/image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIXME**: Colab notebook with an example: ![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python -m plant_pathology.train -h\n",
    "usage: train.py [-h] [--frz FRZ] [--pre PRE] [--re RE] [--bs BS] [--smooth] [--arch ARCH] [--dump] [--log] [--save] [--mixup MIXUP] [--tta] [--fp16] [--eval_dir EVAL_DIR] [--val_fold VAL_FOLD] [--pseudo PSEUDO] path epochs lr\n",
    "\n",
    "positional arguments:\n",
    "  path                 Path to data dir\n",
    "  epochs               Number of unfrozen epochs\n",
    "  lr                   Initial learning rate\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help           show this help message and exit\n",
    "  --frz FRZ            Number of frozen epochs (default: 1)\n",
    "  --pre PRE            Image presize (default: (682, 1024))\n",
    "  --re RE              Image resize (default: 256)\n",
    "  --bs BS              Batch size (default: 256)\n",
    "  --smooth             Label smoothing? (default: False)\n",
    "  --arch ARCH          Architecture (default: resnet18)\n",
    "  --dump               Don't train, just print model (default: False)\n",
    "  --log                Log w/ W&B (default: False)\n",
    "  --save               Save model based on RocAuc (default: False)\n",
    "  --mixup MIXUP        Mixup (0.4 is good) (default: 0.0)\n",
    "  --tta                Test-time augmentation (default: False)\n",
    "  --fp16               Mixed-precision training (default: False)\n",
    "  --eval_dir EVAL_DIR  Evaluate model and save results in dir\n",
    "  --val_fold VAL_FOLD  Don't go cross-validation, just do 1 fold (or pass 9 to train on all data)\n",
    "  --pseudo PSEUDO      Path to pseudo labels to train on\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "To run the tests found in all the notebook in parallel, just run `nbdev_test_nbs` from the terminal! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_dataset.ipynb.\n",
      "Converted 02_evaluate.ipynb.\n",
      "Converted 03_train.ipynb.\n",
      "Converted 04_generate_pseudo_labels.ipynb.\n",
      "Converted 05_self_knowledge_distillation.ipynb.\n",
      "Converted 06_create_folds.ipynb.\n",
      "Converted config.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
