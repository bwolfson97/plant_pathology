{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "> This module contains a script to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from plant_pathology.config import DATA_PATH\n",
    "from plant_pathology.dataset import get_dls\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sys import exit\n",
    "from typing import Any, Callable, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "from fastai.callback.wandb import WandbCallback, wandb\n",
    "from fastai.vision.all import *\n",
    "from wwf.vision.timm import timm_learner\n",
    "\n",
    "from plant_pathology.dataset import get_dls_all_in_1\n",
    "from plant_pathology.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model on Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def timm_or_fastai_arch(arch: str) -> Tuple[Union[Any, str], Callable[..., Learner]]:\n",
    "    try:  # Check if fastai arch\n",
    "        model = globals()[arch]\n",
    "        learner_func = cnn_learner\n",
    "    except KeyError:  # Must be timm arch\n",
    "        model = arch\n",
    "        learner_func = timm_learner\n",
    "    return model, learner_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train(\n",
    "    data_path: Path, epochs: int = 1, lr: Union[float, str] = 3e-4, frz: int=1, pre: int=800, re: int=256,\n",
    "    bs: int=200, fold: int=4, smooth: bool=False,\n",
    "    arch: str='resnet18', dump: bool=False, log: bool=False, mixup: float=0.,\n",
    "    fp16: bool=False, dls: DataLoaders=None, save: bool=False, pseudo: Path=None,\n",
    " ) -> Learner:\n",
    "    # Prep Data, Opt, Loss, Arch\n",
    "    if dls is None:\n",
    "        dls = get_dls_all_in_1(\n",
    "            data_path=data_path, presize=pre, resize=re, bs=bs, val_fold=fold, pseudo_labels_path=pseudo\n",
    "        )\n",
    "    if log: wandb.init(project=\"plant-pathology\")\n",
    "    if smooth: loss_func = LabelSmoothingCrossEntropyFlat()\n",
    "    else:      loss_func = CrossEntropyLossFlat()\n",
    "    m, learner_func = timm_or_fastai_arch(arch)\n",
    "\n",
    "    # Add callbacks\n",
    "    cbs = [SaveModelCallback(\"roc_auc_score\", fname=f\"model_val_on_{fold}\")] if save or log else []\n",
    "    if log: cbs.append(WandbCallback())\n",
    "    if mixup: cbs.append(MixUp(mixup))\n",
    "\n",
    "    # Build learner\n",
    "    print(f\"# train exs: {len(dls.train_ds)}, val exs: {len(dls.valid_ds)}\")\n",
    "    learn = learner_func(dls, m, loss_func=loss_func,\n",
    "                    metrics=[accuracy, RocAuc()], cbs=cbs)\n",
    "    if dump: print(learn.model); exit()\n",
    "    if lr==\"find\": learn.lr_find(); exit()\n",
    "    if fp16: learn.to_fp16()\n",
    "\n",
    "    # Train\n",
    "    learn.freeze()\n",
    "    learn.fit_one_cycle(frz, lr)\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(epochs, slice(lr/100, lr/2))  # Explore other divs\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train exs: 1457, val exs: 364\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.950449</td>\n",
       "      <td>1.180670</td>\n",
       "      <td>0.508242</td>\n",
       "      <td>0.749386</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide\n",
    "learn = train(DATA_PATH, epochs=0, lr=0.001, bs=256, log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def softmax_RocAuc(logits, labels):\n",
    "    probs = logits.softmax(-1)\n",
    "    return RocAuc()(probs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4090,  1.6367, -0.1251,  1.2801],\n",
       "         [-1.3648,  0.4716, -2.0059, -0.8697]]),\n",
       " torch.Size([4, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "preds = torch.randn(2, 4)\n",
    "labels = tensor([1, 2, 3, 4]).unsqueeze(-1)\n",
    "preds, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def train_cv(\n",
    "    path:     Param(\"Path to data dir\", Path),\n",
    "    epochs:   Param(\"Number of unfrozen epochs\", int)=1,\n",
    "    lr:       Param(\"Initial learning rate\", float)=3e-4,\n",
    "    frz:      Param(\"Number of frozen epochs\", int)=1,\n",
    "    pre:      Param(\"Image presize\", int, nargs=\"+\")=(682, 1024),\n",
    "    re:       Param(\"Image resize\", int)=256,\n",
    "    bs:       Param(\"Batch size\", int)=256,\n",
    "    smooth:   Param(\"Label smoothing?\", store_true)=False,\n",
    "    arch:     Param(\"Architecture\", str)='resnet18',\n",
    "    dump:     Param(\"Don't train, just print model\", store_true)=False,\n",
    "    log:      Param(\"Log w/ W&B\", store_true)=False,\n",
    "    save:     Param(\"Save model based on RocAuc\", store_true)=False,\n",
    "    mixup:    Param(\"Mixup (0.4 is good)\", float)=0.0,\n",
    "    tta:      Param(\"Test-time augmentation\", store_true)=False,\n",
    "    fp16:     Param(\"Mixed-precision training\", store_true)=False,\n",
    "    do_eval:  Param(\"Evaluate model and save predictions CSV\", store_true)=False,\n",
    "    val_fold: Param(\"Don't go cross-validation, just do 1 fold (or pass 9 \"\n",
    "                    \"to train on all data)\", int)=None,\n",
    "    pseudo:   Param(\"Path to pseudo labels to train on\", Path)=None,\n",
    "    export:   Param(\"Export learner(s) to export_val_on_{fold}.pkl\", store_true)=False,\n",
    "):\n",
    "    print(locals())\n",
    "    scores = []\n",
    "    for fold in range(5):\n",
    "        if val_fold is not None: fold = val_fold  # Not doing CV\n",
    "        print(f\"\\nTraining on fold {fold}\")\n",
    "        learn = train(data_path=path, epochs=epochs, lr=lr, frz=frz, pre=pre,\n",
    "                      re=re, bs=bs, smooth=smooth, arch=arch, dump=dump, log=log,\n",
    "                      fold=fold, mixup=mixup, fp16=fp16, save=save, pseudo=pseudo)\n",
    "\n",
    "        if hasattr(learn, \"mixup\") and tta: learn.remove_cb(MixUp)  # Bug when doing tta w/Mixup\n",
    "\n",
    "        if tta and val_fold != 9:  # There IS a valid set\n",
    "            preds, lbls = learn.tta()\n",
    "            res = [f(preds, lbls) for f in [learn.loss_func, accuracy, softmax_RocAuc]]\n",
    "        else: res = learn.final_record\n",
    "        scores.append(res)\n",
    "\n",
    "        # Create submission file for this model\n",
    "        if do_eval: print(\"Evaluating\"); evaluate(learn, path=path/\"test.csv\", name=f\"predictions_fold_{fold}.csv\", tta=tta)\n",
    "\n",
    "        if export: learn.export(f\"export_val_on_{fold}.pkl\")\n",
    "        # Delete learner to avoid OOM\n",
    "        del learn\n",
    "        if val_fold is not None: break\n",
    "    scores = np.array(scores)\n",
    "    print(f\"Scores: {scores}\\n\")\n",
    "    if val_fold is None: print(f\"Mean: {scores.mean(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = np.ones((5, 4))\n",
    "scores.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': Path('../data'), 'epochs': 0, 'lr': 0.02, 'frz': 1, 'pre': 64, 're': 64, 'bs': 512, 'smooth': False, 'arch': 'resnet18', 'dump': False, 'log': False, 'save': False, 'mixup': 0.4, 'tta': True, 'fp16': True, 'do_eval': True, 'val_fold': 4, 'pseudo': None, 'export': True}\n",
      "\n",
      "Training on fold 4\n",
      "# train exs: 1457, val exs: 364\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.366835</td>\n",
       "      <td>5.700662</td>\n",
       "      <td>0.151099</td>\n",
       "      <td>0.559646</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='0' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandon/miniconda3/lib/python3.8/site-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='0' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandon/miniconda3/lib/python3.8/site-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [[1.50433147 0.13736264 0.57773272]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "#hide\n",
    "train_cv(DATA_PATH, 0, 2e-2, pre=64, re=64, bs=512, fp16=True, val_fold=4, tta=True, mixup=0.4, do_eval=True, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "#hide\n",
    "# Check predictions CSV was saved\n",
    "preds_path = Path(\"predictions_fold_4.csv\")\n",
    "assert preds_path.exists(), \"Predictions CSV not saved properly\"\n",
    "preds_path.unlink()\n",
    "\n",
    "# Check Learner was exported properly\n",
    "export_path = Path(\"export_val_on_4.pkl\")\n",
    "assert export_path.exists(), \"Learner not exported properly\"\n",
    "export_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_dataset.ipynb.\n",
      "Converted 02_evaluate.ipynb.\n",
      "Converted 03_train.ipynb.\n",
      "Converted 04_generate_pseudo_labels.ipynb.\n",
      "Converted 05_self_knowledge_distillation.ipynb.\n",
      "Converted 06_create_folds.ipynb.\n",
      "Converted 07_pretrained_models.ipynb.\n",
      "Converted config.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
