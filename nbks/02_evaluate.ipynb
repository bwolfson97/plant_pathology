{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "> This module contains functions to infer on the test set and generate the final submission file for Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "from plant_pathology.config import TEST_DATA_PATH\n",
    "from plant_pathology.utils import load_data\n",
    "from plant_pathology.dataset import get_dls\n",
    "from fastai.vision.all import *\n",
    "from torch.nn import Linear\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Union\n",
    "\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def infer_on_test_set(\n",
    "    learn: Learner,\n",
    "    path: Path,\n",
    "    tta: bool = False,\n",
    "    bs: int = 64,\n",
    ") -> Tensor:\n",
    "    \"\"\"Infers on test CSV at `path` using `learn`, optionally performing TTA.\"\"\"\n",
    "    df_test = pd.read_csv(path)\n",
    "    test_dl = learn.dls.test_dl(df_test, bs=bs)\n",
    "    preds, _ = (learn.tta if tta else learn.get_preds)(dl=test_dl)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "class PredictSingleStep(Callback):\n",
    "    \"\"\"Callback to limit prediction to only first batch.\"\"\"\n",
    "    def __init__(self): \n",
    "        self.step_count = 0\n",
    "    def after_batch(self):\n",
    "        if self.step_count >= 1:\n",
    "            raise CancelValidException\n",
    "        self.step_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# Build learner to test inference\n",
    "path, df = load_data(TEST_DATA_PATH, with_folds=True)\n",
    "dls = get_dls(path, df, presize=32, resize=32, bs=3)\n",
    "simple_model = sequential(AdaptiveAvgPool(), Flatten(), Linear(3, dls.c))\n",
    "learn = Learner(dls, simple_model, loss_func=CrossEntropyLossFlat())#, cbs=[PredictSingleStep()])\n",
    "test_csv_path = TEST_DATA_PATH/\"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = infer_on_test_set(learn, path=test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# Test probabilities all sum to 1.\n",
    "test_close(preds.sum(1), 1.)  # cnn_learner applies softmax after tta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def format_submission(preds: Tensor, save_path: Union[Path, str]) -> Path:\n",
    "    \"\"\"Formats raw `preds` into submission CSV, saving at `save_path`.\"\"\"\n",
    "    # Build submission CSV\n",
    "    image_filenames = [f\"Test_{i}\" for i in range(len(preds))]\n",
    "    column_names = [\"healthy\", \"multiple_diseaes\", \"rust\", \"scab\"]\n",
    "    submission = pd.DataFrame(preds, index=image_filenames, columns=column_names)\n",
    "\n",
    "    # Make parent dirs\n",
    "    save_path = Path(save_path)\n",
    "    Path(save_path.parent).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save submission\n",
    "    submission.to_csv(save_path)\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('TESTING.csv')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = torch.zeros(1821, 4)\n",
    "save_path = format_submission(fake_preds, \"TESTING.csv\"); save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert save_path.exists()\n",
    "save_path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-One Learner -> Submission Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def evaluate(\n",
    "    learn: Learner, path: Path, name: str = \"submission.csv\", tta: bool = False\n",
    ") -> Path:\n",
    "    \"\"\"Evaluates `learn` on test CSV at `path` and saves as `name`, optionally applying TTA.\"\"\"\n",
    "    preds = infer_on_test_set(learn, path=path, tta=tta)\n",
    "    return format_submission(preds, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_dataset.ipynb.\n",
      "Converted 02_evaluate.ipynb.\n",
      "Converted 03_train.ipynb.\n",
      "Converted 04_generate_pseudo_labels.ipynb.\n",
      "Converted 05_self_knowledge_distillation.ipynb.\n",
      "Converted 06_create_folds.ipynb.\n",
      "Converted 07_pretrained_models.ipynb.\n",
      "Converted config.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
